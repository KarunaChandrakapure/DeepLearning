{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2083feb-65b2-4bbe-ab41-57a7d2a1ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e34a0ee-76b1-454d-82bc-39a3f95933e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1631 files belonging to 2 classes.\n",
      "Found 340 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    '/media/karuna/Windows/karuna/DeepLearning/base_data_cycle1_Feb6/train',\n",
    "    labels='inferred',\n",
    "    image_size=(224,224),\n",
    "    batch_size=32)\n",
    "    \n",
    "val_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    '/media/karuna/Windows/karuna/DeepLearning/base_data_cycle1_Feb6/val',\n",
    "    labels='inferred',\n",
    "    image_size=(224,224),\n",
    "    batch_size=32)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f8f4b1-d67d-49c9-a935-93d8058f7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "043d49e1-6c8e-498e-a9c2-48ba3c0eb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda x,y:(normalization_layer(x),y))\n",
    "val_dataset = val_dataset.map(lambda x,y:(normalization_layer(x),y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84679603-cfda-4c44-ab66-5bacae93ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 186624)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               95552000  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95,572,418\n",
      "Trainable params: 95,572,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(224, 224, 3)),  \n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(2, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7fdd84c-c53c-4965-83d0-09ec0c18ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer= keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics =[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e3a6449-9330-4bc3-bbe2-ec39b7385284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 - 2s - loss: 2.0251 - accuracy: 0.7106 - 2s/epoch - 48ms/step\n",
      "Epoch 2/5\n",
      "51/51 - 2s - loss: 0.1990 - accuracy: 0.9221 - 2s/epoch - 43ms/step\n",
      "Epoch 3/5\n",
      "51/51 - 2s - loss: 0.0885 - accuracy: 0.9700 - 2s/epoch - 43ms/step\n",
      "Epoch 4/5\n",
      "51/51 - 2s - loss: 0.0296 - accuracy: 0.9926 - 2s/epoch - 44ms/step\n",
      "Epoch 5/5\n",
      "51/51 - 2s - loss: 0.0166 - accuracy: 0.9963 - 2s/epoch - 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c348da280>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,batch_size=16,epochs=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d71b901-5176-44ab-b9ba-e8d0ca2dad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0670056e-06 9.9999809e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "image_path = 'base_data_cycle1_Feb6/live_images/Screenshot from 2025-03-07 15-33-23.png'\n",
    "image = keras.utils.load_img(image_path, target_size=(224, 224))  \n",
    "input_arr = keras.utils.img_to_array(image)\n",
    "input_arr = input_arr / 255.0  \n",
    "input_arr = np.expand_dims(input_arr, axis=0)  \n",
    "predictions = model.predict(input_arr)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac35226-9dd4-4f31-b96c-c570d61af954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
